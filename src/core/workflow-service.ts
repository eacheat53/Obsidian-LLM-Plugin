import { App, Notice, TFile } from 'obsidian';
import { PluginSettings } from '../plugin-settings';
import { CacheService } from '../storage/cache-service';
import { NoteProcessorService } from './note-processor';
import { APIService } from '../services/api-service';
import { AIService } from './ai-service';
import { LinkInjectorService } from './link-injector';
import { FailureLogService } from '../services/log-service';
import { TaskManagerService } from '../services/task-manager';
import { NotifierService } from '../services/notifier';
import { ErrorLogger } from '../utils/error-logger';
import { NoteId, NotePairScore } from '../types/index';
import { MasterIndex } from '../types/cache-types';
import { parseFrontMatter } from '../utils/frontmatter-parser';

export class WorkflowService {
    private app: App;
    private settings: PluginSettings;
    private cacheService: CacheService;
    private noteProcessorService: NoteProcessorService;
    private apiService: APIService;
    private aiService: AIService;
    private linkInjectorService: LinkInjectorService;
    private taskManagerService: TaskManagerService;
    private failureLogService: FailureLogService;
    private notifier: NotifierService;
    private errorLogger: ErrorLogger;

    constructor(
        app: App,
        settings: PluginSettings,
        cacheService: CacheService,
        noteProcessorService: NoteProcessorService,
        apiService: APIService,
        aiService: AIService,
        linkInjectorService: LinkInjectorService,
        taskManagerService: TaskManagerService,
        failureLogService: FailureLogService,
        notifier: NotifierService,
        errorLogger: ErrorLogger
    ) {
        this.app = app;
        this.settings = settings;
        this.cacheService = cacheService;
        this.noteProcessorService = noteProcessorService;
        this.apiService = apiService;
        this.aiService = aiService;
        this.linkInjectorService = linkInjectorService;
        this.taskManagerService = taskManagerService;
        this.failureLogService = failureLogService;
        this.notifier = notifier;
        this.errorLogger = errorLogger;
    }

    // ============================================================================================
    // Public Workflows (Composed Pipelines)
    // ============================================================================================

    /**
     * ç”Ÿæˆ/æ›´æ–°åµŒå…¥å·¥ä½œæµ
     * æµç¨‹ï¼šåˆå§‹åŒ– -> å‡†å¤‡æ–‡ä»¶ -> æ›´æ–°åµŒå…¥ -> (å¯é€‰)æ›´æ–°åˆ†æ•° -> (å¯é€‰)æ›´æ–°é“¾æ¥ -> (å¯é€‰)æ›´æ–°æ ‡ç­¾
     */
    async generateEmbeddingsWorkflow(targetPath: string, forceMode: boolean = false): Promise<void> {
        try {
            await this.taskManagerService.startTask('Generate Embeddings', async (updateProgress) => {
                this.notifier.beginProgress('notices.starting', { mode: forceMode ? 'å¼ºåˆ¶' : 'æ™ºèƒ½' });

                // 1. åˆå§‹åŒ–
                const masterIndex = await this.initializeWorkflow(updateProgress);

                // 2. å‡†å¤‡æ–‡ä»¶
                const files = await this.prepareFiles(targetPath, updateProgress);
                if (files.length === 0) return;

                // 3. æ›´æ–°åµŒå…¥
                const changedNoteIds = await this.updateEmbeddings(files, masterIndex, forceMode, updateProgress);

                // 4. åç»­å¤„ç†ï¼ˆå¦‚æœå‘ç”Ÿå˜æ›´ï¼‰
                if (changedNoteIds.size > 0) {
                    // 4.1 æ›´æ–°åˆ†æ•°
                    const filteredPairs = await this.updateScores(masterIndex, changedNoteIds, files, updateProgress);

                    // 4.2 æ›´æ–°é“¾æ¥
                    // å³ä½¿æ²¡æœ‰æ–°é…å¯¹ï¼Œä¹Ÿéœ€è¦è¿è¡Œä»¥ç§»é™¤æ—§é“¾æ¥ï¼ˆé’ˆå¯¹å·²å˜æ›´çš„ç¬”è®°ï¼‰
                    await this.reconcileLinks(files, masterIndex, filteredPairs, changedNoteIds, updateProgress);
                }

                // 5. æ›´æ–°æ ‡ç­¾ (ç‹¬ç«‹å¤„ç†ï¼Œä¸å®Œå…¨ä¾èµ– changedNoteIds)
                await this.updateTags(files, masterIndex, changedNoteIds, forceMode, updateProgress);

                updateProgress(100, 'Done!');
                this.notifier.endProgress();
                this.notifier.success('notices.finished');
            });
        } catch (error) {
            this.handleWorkflowError(error, 'Generate embeddings workflow failed');
        }
    }

    /**
     * ä¸»å·¥ä½œæµï¼šå¤„ç†ç¬”è®°å¹¶æ’å…¥å»ºè®®çš„é“¾æ¥
     * ï¼ˆæ—§ç‰ˆç»„åˆå·¥ä½œæµ - ç°å·²é‡æ„ä¸ºå¤ç”¨ generateEmbeddingsWorkflow çš„é€»è¾‘ï¼‰
     */
    async processNotesWorkflow(targetPath?: string, forceMode: boolean = false): Promise<void> {
        // å¤ç”¨ generateEmbeddingsWorkflowï¼Œå› ä¸ºé€»è¾‘å®Œå…¨ä¸€è‡´
        return this.generateEmbeddingsWorkflow(targetPath || this.settings.default_scan_path, forceMode);
    }

    /**
     * ä¸€é”®æ‰§è¡Œå·¥ä½œæµï¼ˆå•çº¿ä»»åŠ¡ï¼‰
     */
    async runSinglePipelineWorkflow(targetPath: string, forceMode: boolean = false): Promise<void> {
        return this.generateEmbeddingsWorkflow(targetPath, forceMode);
    }

    /**
     * æ‰¹é‡æ’å…¥ AI æ ‡ç­¾å·¥ä½œæµ
     * æµç¨‹ï¼šåˆå§‹åŒ– -> å‡†å¤‡æ–‡ä»¶ -> æ›´æ–°æ ‡ç­¾
     */
    async batchInsertTagsWorkflow(targetPath: string, forceMode: boolean): Promise<void> {
        try {
            await this.taskManagerService.startTask('Batch Insert AI Tags', async (updateProgress) => {
                // 1. åˆå§‹åŒ–
                const masterIndex = await this.initializeWorkflow(updateProgress);

                // 2. å‡†å¤‡æ–‡ä»¶
                const files = await this.prepareFiles(targetPath, updateProgress);
                if (files.length === 0) return;

                // 3. æ›´æ–°æ ‡ç­¾
                // æ³¨æ„ï¼šè¿™é‡Œä¼ é€’ç©ºçš„ changedNoteIdsï¼Œå› ä¸ºæˆ‘ä»¬åªå…³å¿ƒ forceMode æˆ–ç¼ºå¤±æ ‡ç­¾çš„æƒ…å†µ
                await this.updateTags(files, masterIndex, new Set<NoteId>(), forceMode, updateProgress);

                updateProgress(100, 'Done!');
                this.notifier.endProgress();
                this.notifier.success('notices.finished');
            });
        } catch (error) {
            this.handleWorkflowError(error, 'Batch insert tags workflow failed');
        }
    }

    /**
     * é‡æ–°æ ¡å‡†é“¾æ¥å·¥ä½œæµ
     * æµç¨‹ï¼šåˆå§‹åŒ– -> å‡†å¤‡æ–‡ä»¶ -> æ ¡å‡†é“¾æ¥ï¼ˆåŸºäºç°æœ‰åˆ†æ•°ï¼‰
     */
    async recalibrateLinksWorkflow(targetPath: string): Promise<void> {
        try {
            await this.taskManagerService.startTask('Recalibrate Links', async (updateProgress) => {
                this.notifier.beginProgress('notices.starting', { mode: 'é“¾æ¥æ ¡å‡†' });

                // 1. åˆå§‹åŒ– (ä¸æ£€æµ‹å­¤å„¿ï¼Œä¸åˆ›å»º)
                updateProgress(0, 'Loading cache...');
                const loadResult = await this.cacheService.loadMasterIndex({
                    detect_orphans: false,
                    create_if_missing: false
                });

                if (!loadResult.success || !loadResult.index) {
                    throw new Error('Failed to load master index. Please run embedding generation first.');
                }
                const masterIndex = loadResult.index;

                // æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„ scores
                const scoreCount = Object.keys(masterIndex.scores || {}).length;
                if (scoreCount === 0) {
                    new Notice('No scores found. Please run the main workflow first to generate scores.');
                    return;
                }

                // 2. å‡†å¤‡æ–‡ä»¶
                const files = await this.prepareFiles(targetPath, updateProgress);
                if (files.length === 0) return;

                // 3. æ ¡å‡†é“¾æ¥ (ä½¿ç”¨å…¨é‡ scores)
                // ä¼ é€’æ‰€æœ‰æ–‡ä»¶ä½œä¸º affected files
                const allNoteIds = new Set<NoteId>(); // ç©ºé›†åˆæ„å‘³ç€å¤„ç†æ‰€æœ‰ä¼ å…¥çš„ files
                await this.reconcileLinks(files, masterIndex, [], allNoteIds, updateProgress, true);

                updateProgress(100, 'Done!');
                this.notifier.endProgress();
            });
        } catch (error) {
            this.handleWorkflowError(error, 'Recalibrate links workflow failed');
        }
    }

    // ============================================================================================
    // Atomic Steps (Private Methods)
    // ============================================================================================

    /**
     * æ­¥éª¤ 1: åˆå§‹åŒ–å·¥ä½œæµï¼ŒåŠ è½½ä¸»ç´¢å¼•
     */
    private async initializeWorkflow(updateProgress: (progress: number, message: string) => void): Promise<MasterIndex> {
        updateProgress(0, 'Loading cache...');
        const loadResult = await this.cacheService.loadMasterIndex({
            detect_orphans: true,
            create_if_missing: true
        });

        if (!loadResult.success || !loadResult.index) {
            throw new Error('Failed to load master index');
        }

        return loadResult.index;
    }

    /**
     * æ­¥éª¤ 2: æ‰«æå¹¶å‡†å¤‡æ–‡ä»¶ (æ·»åŠ  HASH_BOUNDARY)
     */
    private async prepareFiles(targetPath: string, updateProgress: (progress: number, message: string) => void): Promise<TFile[]> {
        updateProgress(5, 'Scanning vault...');
        const files = await this.noteProcessorService.scanVault(targetPath);

        if (files.length === 0) {
            new Notice('No files found to process');
            return [];
        }

        updateProgress(10, 'Checking hash boundaries...');
        let filesWithoutBoundary = 0;

        for (const file of files) {
            const content = await this.app.vault.read(file);
            if (!content.includes('<!-- HASH_BOUNDARY -->')) {
                filesWithoutBoundary++;
            }
        }

        if (filesWithoutBoundary > 0) {
            new Notice(`Adding HASH_BOUNDARY to ${filesWithoutBoundary} notes...`);
            await this.noteProcessorService.addHashBoundaryToNotes(files);
        }

        return files;
    }

    /**
     * æ­¥éª¤ 3: æ›´æ–°åµŒå…¥ (Embeddings)
     * è¿”å›å·²æ›´æ”¹çš„ NoteId é›†åˆ
     */
    private async updateEmbeddings(
        files: TFile[],
        masterIndex: MasterIndex,
        forceMode: boolean,
        updateProgress: (progress: number, message: string) => void
    ): Promise<Set<NoteId>> {
        updateProgress(15, 'Generating embeddings...');
        let newEmbeddingsCount = 0;
        let skippedCount = 0;
        const changedNoteIds = new Set<NoteId>();

        // è·å–å¤±è´¥çš„ç¬”è®° ID (æ™ºèƒ½é‡è¯•)
        const failedNoteIds = this.failureLogService
            ? await this.failureLogService.getFailedNoteIdsByType('embedding')
            : new Set<NoteId>();

        if (failedNoteIds.size > 0 && this.settings.enable_debug_logging) {
            console.log(`[Workflow] å‘ç° ${failedNoteIds.size} ä¸ªå¤±è´¥çš„åµŒå…¥æ“ä½œï¼Œå°†å¼ºåˆ¶é‡è¯•`);
        }

        for (let i = 0; i < files.length; i++) {
            const file = files[i];
            const noteId = await this.noteProcessorService.ensureNoteHasId(file);
            const mainContent = await this.noteProcessorService.extractMainContent(file);
            const contentHash = await this.noteProcessorService.calculateContentHash(file);

            const existingNote = masterIndex.notes[noteId];
            let needsUpdate = forceMode || !existingNote || existingNote.content_hash !== contentHash;

            // å¼ºåˆ¶é‡è¯•å¤±è´¥ç¬”è®°
            if (failedNoteIds.has(noteId) && !needsUpdate) {
                needsUpdate = true;
                if (this.settings.enable_debug_logging) console.log(`[Workflow] å¼ºåˆ¶é‡è¯•å¤±è´¥ç¬”è®°: ${file.basename}`);
            }

            if (!needsUpdate && existingNote) {
                skippedCount++;
                if (this.settings.enable_debug_logging) console.log(`[Workflow] Skipped ${file.basename} (unchanged)`);
            }

            if (needsUpdate || !existingNote) {
                if (this.settings.enable_debug_logging) console.log(`[Workflow] Processing ${file.basename} (${needsUpdate ? 'changed' : 'new'})`);

                try {
                    const response = await this.apiService.callJinaAPI({
                        input: [mainContent],
                        model: this.settings.jina_model_name,
                        note_ids: [noteId],
                    });

                    if (response.data.length > 0) {
                        const embedding = response.data[0].embedding;
                        newEmbeddingsCount++;

                        await this.cacheService.saveEmbedding({
                            note_id: noteId,
                            embedding,
                            model_name: this.settings.jina_model_name,
                            created_at: Date.now(),
                            content_preview: mainContent.substring(0, 200),
                        });

                        const content = await this.app.vault.read(file);
                        masterIndex.notes[noteId] = {
                            note_id: noteId,
                            file_path: file.path,
                            content_hash: contentHash,
                            last_processed: Date.now(),
                            tags: existingNote?.tags || [],
                            has_frontmatter: content.startsWith('---'),
                            has_hash_boundary: content.includes('<!-- HASH_BOUNDARY -->'),
                            has_links_section: content.includes('<!-- LINKS_START -->'),
                        };

                        this.invalidateScoresForNote(masterIndex, noteId);
                        await this.cacheService.saveMasterIndex(masterIndex);
                        this.cacheService.setMasterIndex(masterIndex);

                        // æ¸…é™¤å¤±è´¥è®°å½•
                        if (this.failureLogService) {
                            const failedOps = await this.failureLogService.getUnresolvedFailures();
                            for (const op of failedOps) {
                                if (op.operation_type === 'embedding' && op.batch_info.items.includes(noteId)) {
                                    await this.failureLogService.deleteFailure(op.id);
                                }
                            }
                        }

                        changedNoteIds.add(noteId);
                    }
                } catch (error) {
                    const err = error as Error;
                    console.error(`[Workflow] Failed to generate embedding for ${file.basename}:`, err.message);
                    this.recordFailure('embedding', i, files.length, [noteId], [file.path], err);
                    continue;
                }
            }

            updateProgress(15 + (i / files.length) * 75, `Processed ${i + 1}/${files.length} (${newEmbeddingsCount} new, ${skippedCount} skipped)`);

            if (this.taskManagerService.isCancellationRequested()) {
                throw new Error('Task cancelled by user');
            }
        }

        await this.cacheService.saveMasterIndex(masterIndex);
        this.cacheService.setMasterIndex(masterIndex);

        if (this.settings.enable_debug_logging) {
            console.log(`[Workflow] Embedding ç»Ÿè®¡: æ€»æ•°=${files.length}, æ–°å¢=${newEmbeddingsCount}, è·³è¿‡=${skippedCount}, å˜æ›´=${changedNoteIds.size}`);
        }

        return changedNoteIds;
    }

    /**
     * æ­¥éª¤ 4.1: æ›´æ–°åˆ†æ•° (Scores)
     * ä»…è®¡ç®—å˜æ›´ç¬”è®°çš„ç›¸ä¼¼åº¦å¹¶è¯„åˆ†
     */
    private async updateScores(
        masterIndex: MasterIndex,
        changedNoteIds: Set<NoteId>,
        files: TFile[],
        updateProgress: (progress: number, message: string) => void
    ): Promise<NotePairScore[]> {
        updateProgress(90, 'Scoring changed notes...');

        const embeddings = new Map<string, number[]>();
        for (const [noteId, meta] of Object.entries(masterIndex.notes)) {
            const emb = await this.cacheService.loadEmbedding(noteId as NoteId);
            if (emb.success && emb.embedding) {
                embeddings.set(noteId, emb.embedding);
            }
        }

        let pairs = await this.aiService.calculateSimilaritiesForNotes(embeddings, changedNoteIds);
        pairs = this.dedupePairs(pairs);

        if (pairs.length === 0) return [];

        this.notifier.info('notices.scoringPairs', { count: pairs.length });
        const scoredPairs = await this.aiService.scorePairs(pairs);
        const filteredPairs = this.aiService.filterByThresholds(scoredPairs);
        this.logPairsReadable(masterIndex, filteredPairs, 'è¿‡æ»¤åè¯„åˆ†å“åº”');

        for (const pair of filteredPairs) {
            const pairKey = `${pair.note_id_1}:${pair.note_id_2}`;
            masterIndex.scores[pairKey] = pair;
        }

        await this.cacheService.saveMasterIndex(masterIndex);
        return filteredPairs;
    }

    /**
     * æ­¥éª¤ 4.2: æ ¡å‡†é“¾æ¥ (Reconcile Links)
     * æ ¹æ®åˆ†æ•°æ’å…¥æˆ–åˆ é™¤é“¾æ¥
     */
    private async reconcileLinks(
        files: TFile[],
        masterIndex: MasterIndex,
        newPairs: NotePairScore[],
        changedNoteIds: Set<NoteId>,
        updateProgress: (progress: number, message: string) => void,
        fullRecalibration: boolean = false
    ): Promise<void> {
        updateProgress(92, 'Inserting/Recalibrating links...');

        // è®¡ç®—å—å½±å“çš„ç¬”è®°é›†åˆ
        let affected = new Set<NoteId>();

        if (fullRecalibration) {
            // å…¨é‡æ¨¡å¼ï¼šæ‰€æœ‰ä¼ å…¥çš„æ–‡ä»¶éƒ½è§†ä¸ºå—å½±å“
            // æˆ‘ä»¬éœ€è¦å°† files è½¬æ¢ä¸º noteIds
            for (const file of files) {
                // è¿™é‡Œå‡è®¾ prepareFiles å·²ç»ç¡®ä¿äº† noteId å­˜åœ¨ï¼Œæˆ–è€…æˆ‘ä»¬å†æ¬¡ç¡®ä¿
                // ä¸ºäº†æ€§èƒ½ï¼Œæˆ‘ä»¬å°è¯•ä» masterIndex è·å–ï¼Œå¦‚æœä¸è¡Œå†è¯»å–æ–‡ä»¶
                // ä½†ç”±äº files æ˜¯ TFile[]ï¼Œæˆ‘ä»¬æœ€å¥½å†æ¬¡ ensureNoteHasId (å®ƒæ˜¯å¹‚ç­‰çš„ä¸”å¾ˆå¿«)
                const nid = await this.noteProcessorService.ensureNoteHasId(file);
                affected.add(nid);
            }
        } else {
            // å¢é‡æ¨¡å¼ï¼šå˜æ›´ + æ–°é…å¯¹ + åå‘é‚»å±…
            affected = new Set<NoteId>([...Array.from(changedNoteIds)]);
            for (const p of newPairs) { affected.add(p.note_id_1); affected.add(p.note_id_2); }

            // åå‘é‚»å±…
            const reverseAffected = new Set<NoteId>();
            const ledger = masterIndex.link_ledger || {} as Record<NoteId, NoteId[]>;
            for (const srcId in ledger) {
                const targets = ledger[srcId] || [];
                for (const changedId of changedNoteIds) {
                    if (targets.includes(changedId)) { reverseAffected.add(srcId as NoteId); break; }
                }
            }
            for (const id of Array.from(reverseAffected)) affected.add(id);
        }

        // æ˜ å°„ NoteId -> TFile
        const fileMap: Record<string, TFile> = {};
        for (const file of files) {
            const nid = await this.noteProcessorService.ensureNoteHasId(file);
            if (affected.has(nid)) fileMap[nid] = file;
        }

        let totalReconciled = 0;
        let processedCount = 0;
        const affectedList = Array.from(affected);

        for (let i = 0; i < affectedList.length; i++) {
            const nid = affectedList[i];
            const f = fileMap[nid];
            if (!f) continue;

            const desired = this.linkInjectorService.getDesiredTargetsFromScores(nid, masterIndex.scores);
            const res = await this.linkInjectorService.reconcileUsingLedger(f, nid, desired);
            totalReconciled += res.added + res.removed;
            processedCount++;

            if (fullRecalibration) {
                updateProgress(20 + (i / affectedList.length) * 75, `Processed ${i + 1}/${affectedList.length} notes`);
            }
        }

        await this.cacheService.saveMasterIndex(masterIndex); // ä¿å­˜ ledger æ›´æ–°

        if (this.settings.enable_debug_logging) {
            console.log(`[Workflow] é“¾æ¥æ ¡å‡†å®Œæˆ: å—å½±å“=${affected.size}, å˜æ›´=${totalReconciled}`);
        }

        if (fullRecalibration) {
            if (processedCount === 0) {
                new Notice('âœ… All links already match current thresholds. No changes needed.');
            } else {
                new Notice(`âœ… Recalibrated ${processedCount} notes: changed ${totalReconciled} links`);
            }
        }
    }

    /**
     * æ­¥éª¤ 5: æ›´æ–°æ ‡ç­¾ (Tags)
     */
    private async updateTags(
        files: TFile[],
        masterIndex: MasterIndex,
        changedNoteIds: Set<NoteId>,
        forceMode: boolean,
        updateProgress: (progress: number, message: string) => void
    ): Promise<void> {
        updateProgress(95, 'Generating tags...');

        const notesNeedingTags = new Set<NoteId>([...changedNoteIds]);

        // æ£€æŸ¥æœªå®Œæˆæ ‡ç­¾çš„ç¬”è®°
        for (const [noteId, metadata] of Object.entries(masterIndex.notes)) {
            // æ™ºèƒ½æ£€æŸ¥ï¼šå¦‚æœ forceMode æˆ– (æ²¡æœ‰ç”Ÿæˆè¿‡æ ‡ç­¾ ä¸” æœ‰ embedding)
            // æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ä¸»è¦ä¾èµ– changedNoteIdsï¼Œä½†ä¹Ÿè¦è¡¥æ¼
            const shouldCheck = forceMode || !metadata.tags_generated_at;
            if (shouldCheck) {
                const embResult = await this.cacheService.loadEmbedding(noteId as NoteId);
                if (embResult.success && embResult.embedding) {
                    notesNeedingTags.add(noteId as NoteId);
                }
            }
        }

        // è¿‡æ»¤å‡ºå®é™…åœ¨ files åˆ—è¡¨ä¸­çš„ç¬”è®° (é¿å…å¤„ç†ä¸åœ¨æœ¬æ¬¡æ‰«æèŒƒå›´å†…çš„ç¬”è®°)
        // ä½†å¦‚æœæ˜¯ batchInsertTagsWorkflowï¼Œfiles å°±æ˜¯å…¨éƒ¨ï¼Œæ‰€ä»¥æ²¡é—®é¢˜
        // è¿™é‡Œåšä¸€ä¸ªäº¤é›†æ£€æŸ¥æ¯”è¾ƒå®‰å…¨ï¼Œæˆ–è€…æˆ‘ä»¬å‡è®¾ files åŒ…å«äº†æ‰€æœ‰éœ€è¦å¤„ç†çš„
        // ä¸ºäº†ç®€å•èµ·è§ï¼Œæˆ‘ä»¬åªå¤„ç† notesNeedingTags ä¸­å­˜åœ¨äº masterIndex çš„ (ä¸”æ–‡ä»¶å­˜åœ¨)

        if (notesNeedingTags.size === 0) return;

        const notesList = Array.from(notesNeedingTags);
        if (this.settings.enable_debug_logging) {
            console.log(`[Workflow] éœ€è¦ç”Ÿæˆæ ‡ç­¾: ${notesList.length}`);
            console.log(`[Workflow] å¾…å¤„ç†ç¬”è®° ID:`, notesList);
        }

        // æ„å»º fileMap
        const fileMap: Record<string, TFile> = {};
        for (const nid of notesList) {
            const metadata = masterIndex.notes[nid];
            if (metadata) {
                const file = this.app.vault.getAbstractFileByPath(metadata.file_path) as TFile;
                if (file) fileMap[nid] = file;
            }
        }

        await this.aiService.generateTagsBatch(
            notesList,
            () => this.taskManagerService.isCancellationRequested(),
            async (batchResults: Map<NoteId, string[]>) => {
                for (const [nid, tags] of batchResults) {
                    const file = fileMap[nid];
                    if (!file || !tags || tags.length === 0) continue;

                    try {
                        await this.app.fileManager.processFrontMatter(file, (frontmatter) => {
                            frontmatter['tags'] = tags;
                        });

                        if (masterIndex.notes[nid]) {
                            masterIndex.notes[nid].tags_generated_at = Date.now();
                            // ä½¿ç”¨å¢é‡æ›´æ–°ä¿å­˜ tags_generated_at
                            await this.cacheService.updateNote(nid, masterIndex.notes[nid]);
                        }
                    } catch (err) {
                        console.error(`[Workflow] Failed to update YAML for ${file.path}:`, err);
                    }
                }
                // ä¸éœ€è¦å…¨é‡ä¿å­˜äº†
                // await this.cacheService.saveMasterIndex(masterIndex);
            }
        );

        this.notifier.info('notices.taggingDone', { count: notesList.length }, true);
    }

    // ============================================================================================
    // Utility Workflows (Standalone)
    // ============================================================================================

    async syncHashWorkflow(targetPath: string): Promise<void> {
        try {
            await this.taskManagerService.startTask('Sync Hash', async (updateProgress) => {
                const masterIndex = await this.initializeWorkflow(updateProgress);
                const files = await this.noteProcessorService.scanVault(targetPath);

                if (files.length === 0) {
                    new Notice('æœªæ‰¾åˆ°éœ€è¦å¤„ç†çš„æ–‡ä»¶');
                    return;
                }

                let syncedCount = 0;
                let skippedCount = 0;
                const yamlErrors: string[] = [];

                for (let i = 0; i < files.length; i++) {
                    const file = files[i];
                    updateProgress(10 + (i / files.length) * 80, `Syncing hash ${i + 1}/${files.length}`);

                    const content = await this.app.vault.read(file);
                    const fm = parseFrontMatter(content);

                    if (fm.parseError) {
                        yamlErrors.push(`${file.path}: ${fm.parseError}`);
                        skippedCount++;
                        continue;
                    }

                    if (!fm.data.note_id || typeof fm.data.note_id !== 'string') {
                        skippedCount++;
                        continue;
                    }

                    const noteId = fm.data.note_id as NoteId;
                    const contentHash = await this.noteProcessorService.calculateContentHash(file);

                    const existingNote = masterIndex.notes[noteId];
                    if (existingNote) {
                        existingNote.content_hash = contentHash;
                        existingNote.last_processed = Date.now();
                    } else {
                        masterIndex.notes[noteId] = {
                            note_id: noteId,
                            file_path: file.path,
                            content_hash: contentHash,
                            last_processed: Date.now(),
                            tags: [],
                            has_frontmatter: content.startsWith('---'),
                            has_hash_boundary: content.includes('<!-- HASH_BOUNDARY -->'),
                            has_links_section: content.includes('<!-- LINKS_START -->'),
                        };
                    }
                    syncedCount++;
                }

                await this.cacheService.saveMasterIndex(masterIndex);
                this.cacheService.setMasterIndex(masterIndex);

                updateProgress(100, 'Done');
                if (yamlErrors.length > 0) {
                    new Notice(`âš ï¸ ${yamlErrors.length} ä¸ªç¬”è®°å›  YAML é”™è¯¯è¢«è·³è¿‡`, 10000);
                    console.error('[Workflow] YAML è§£æé”™è¯¯æ±‡æ€»:\n' + yamlErrors.join('\n'));
                }
                new Notice(`âœ… å·²åŒæ­¥ ${syncedCount} ä¸ªç¬”è®°çš„ Hash`);
            });
        } catch (error) {
            this.handleWorkflowError(error, 'Sync hash workflow failed');
        }
    }

    async addHashBoundaryWorkflow(): Promise<void> {
        try {
            const files = await this.noteProcessorService.scanVault(this.settings.default_scan_path);
            if (files.length === 0) {
                new Notice('No files found to process');
                return;
            }
            const modifiedCount = await this.noteProcessorService.addHashBoundaryToNotes(files);
            new Notice(`âœ… Added HASH_BOUNDARY to ${modifiedCount} notes`);
        } catch (error) {
            this.handleWorkflowError(error, 'Add hash boundary failed');
        }
    }

    async addUuidToCurrentNoteWorkflow(): Promise<void> {
        try {
            const noteId = await this.noteProcessorService.addUuidToCurrentNote();
            new Notice(`âœ… Generated UUID: ${noteId}`);
        } catch (error) {
            this.handleWorkflowError(error, 'Add UUID failed');
        }
    }

    async cleanOrphanedDataWorkflow(): Promise<void> {
        try {
            await this.taskManagerService.startTask('Clean Orphaned Data', async (updateProgress) => {
                updateProgress(0, 'Loading cache...');
                const masterIndex = this.cacheService.getMasterIndex();
                if (!masterIndex) {
                    new Notice('âŒ æ— æ³•åŠ è½½ç¼“å­˜');
                    return;
                }

                updateProgress(10, 'Scanning vault...');
                const vaultFiles = this.app.vault.getMarkdownFiles();
                const vaultPaths = new Set(vaultFiles.map(f => f.path));

                updateProgress(20, 'Detecting orphaned notes...');
                const orphanedNoteIds: NoteId[] = [];
                for (const [noteId, meta] of Object.entries(masterIndex.notes)) {
                    if (!vaultPaths.has(meta.file_path)) {
                        orphanedNoteIds.push(noteId as NoteId);
                    }
                }

                if (orphanedNoteIds.length === 0) {
                    new Notice('âœ… æœªå‘ç°å­¤ç«‹æ•°æ®');
                    return;
                }

                updateProgress(40, `Cleaning ${orphanedNoteIds.length} orphaned notes...`);
                let embeddingsDeleted = 0;
                for (const noteId of orphanedNoteIds) {
                    delete masterIndex.notes[noteId];
                    const keysToDelete: string[] = [];
                    for (const key in masterIndex.scores) {
                        if (key.includes(noteId)) keysToDelete.push(key);
                    }
                    for (const key of keysToDelete) {
                        delete masterIndex.scores[key];
                    }
                    try {
                        await this.cacheService.deleteEmbedding(noteId);
                        embeddingsDeleted++;
                    } catch (error) { /* ignore */ }
                }

                updateProgress(70, 'Cleaning broken links...');
                let brokenLinksRemoved = 0;
                if (masterIndex.link_ledger) {
                    const ledger = masterIndex.link_ledger as Record<NoteId, NoteId[]>;
                    const orphanedSet = new Set(orphanedNoteIds);
                    for (const noteId of orphanedNoteIds) delete ledger[noteId];
                    for (const [sourceId, targets] of Object.entries(ledger)) {
                        const filtered = targets.filter(id => !orphanedSet.has(id));
                        if (filtered.length < targets.length) {
                            ledger[sourceId as NoteId] = filtered;
                            brokenLinksRemoved += (targets.length - filtered.length);
                        }
                    }
                }

                await this.cacheService.saveMasterIndex(masterIndex);
                this.cacheService.setMasterIndex(masterIndex);

                updateProgress(100, 'Done');
                new Notice(`âœ… æ¸…ç†å®Œæˆ: ${orphanedNoteIds.length} å­¤ç«‹ç¬”è®°, ${embeddingsDeleted} åµŒå…¥, ${brokenLinksRemoved} æ–­é“¾`);
            });
        } catch (error) {
            this.handleWorkflowError(error, 'Clean orphaned data failed');
        }
    }

    async cacheHealthCheckWorkflow(): Promise<void> {
        try {
            await this.taskManagerService.startTask('Cache Health Check', async (updateProgress) => {
                const masterIndex = this.cacheService.getMasterIndex();
                if (!masterIndex) {
                    new Notice('âŒ æ— æ³•åŠ è½½ç¼“å­˜');
                    return;
                }

                const issues: string[] = [];
                const vaultFiles = this.app.vault.getMarkdownFiles();
                const vaultPaths = new Set(vaultFiles.map(f => f.path));

                let orphanedCount = 0;
                for (const [noteId, meta] of Object.entries(masterIndex.notes)) {
                    if (!vaultPaths.has(meta.file_path)) orphanedCount++;
                }
                if (orphanedCount > 0) issues.push(`ğŸ”¸ ${orphanedCount} ä¸ªå­¤ç«‹ç¬”è®°`);

                let missingUuidCount = 0;
                let missingBoundaryCount = 0;
                for (const file of vaultFiles) {
                    try {
                        const content = await this.app.vault.read(file);
                        const fm = parseFrontMatter(content);
                        if (!fm.data.note_id) missingUuidCount++;
                        if (!content.includes('<!-- HASH_BOUNDARY -->')) missingBoundaryCount++;
                    } catch (e) { /* ignore */ }
                }
                if (missingUuidCount > 0) issues.push(`ğŸ”¸ ${missingUuidCount} ä¸ªç¬”è®°ç¼ºå°‘ note_id`);
                if (missingBoundaryCount > 0) issues.push(`ğŸ”¸ ${missingBoundaryCount} ä¸ªç¬”è®°ç¼ºå°‘ HASH_BOUNDARY`);

                updateProgress(100, 'Done');
                if (issues.length === 0) {
                    new Notice('âœ… ç¼“å­˜å¥åº·çŠ¶å†µè‰¯å¥½');
                } else {
                    new Notice(`âš ï¸ å‘ç°é—®é¢˜:\n${issues.join('\n')}`, 10000);
                    console.log('[Workflow] Health Check:\n' + issues.join('\n'));
                }
            });
        } catch (error) {
            this.handleWorkflowError(error, 'Cache health check failed');
        }
    }

    // ============================================================================================
    // Helpers
    // ============================================================================================

    private handleWorkflowError(error: unknown, context: string) {
        const err = error as Error;
        new Notice(`âŒ Error: ${err.message}`);
        console.error(`[Workflow] ${context}:`, error);
        throw error;
    }

    private async recordFailure(type: 'embedding', batchNum: number, totalBatches: number, items: string[], displayItems: string[], error: Error) {
        if (this.failureLogService) {
            await this.failureLogService.recordFailure({
                operation_type: type,
                batch_info: {
                    batch_number: batchNum,
                    total_batches: totalBatches,
                    items: items,
                    display_items: displayItems,
                },
                error: {
                    message: error.message,
                    type: error.name,
                    stack: error.stack,
                    status: 'status' in error ? (error as any).status : undefined,
                },
            });
        }
        if (this.errorLogger) {
            await this.errorLogger.logBatchFailure({
                operation_type: type,
                batch_number: batchNum,
                total_batches: totalBatches,
                items: items,
                error: error,
                provider: this.settings.ai_provider,
                model: this.settings.jina_model_name,
            });
        }
    }

    private invalidateScoresForNote(masterIndex: any, noteId: NoteId): void {
        const keysToDelete: string[] = [];
        for (const pairKey in masterIndex.scores) {
            const [id1, id2] = pairKey.split(':');
            if (id1 === noteId || id2 === noteId) {
                keysToDelete.push(pairKey);
            }
        }

        if (this.settings.enable_debug_logging && keysToDelete.length > 0) {
            console.log(`[Workflow] Invalidating ${keysToDelete.length} scores for ${noteId}`);
        }

        for (const key of keysToDelete) {
            delete masterIndex.scores[key];
        }
    }

    private logPairsReadable(masterIndex: any, pairs: NotePairScore[], title: string): void {
        if (!this.settings.enable_debug_logging) return;
        try {
            const seen = new Set<string>();
            const lines: string[] = [];
            let count = 0;
            for (const p of pairs) {
                const key = p.note_id_1 < p.note_id_2 ? `${p.note_id_1}:${p.note_id_2}` : `${p.note_id_2}:${p.note_id_1}`;
                if (seen.has(key)) continue;
                seen.add(key);
                const meta1 = masterIndex.notes[p.note_id_1];
                const meta2 = masterIndex.notes[p.note_id_2];
                const name1 = meta1?.file_path || `<missing ${p.note_id_1}>`;
                const name2 = meta2?.file_path || `<missing ${p.note_id_2}>`;
                const ai = typeof p.ai_score === 'number' ? p.ai_score.toString() : 'n/a';
                lines.push(`${name1} <-> ${name2} | è¯„åˆ†=${ai}`);
                count++;
                if (count >= 50) break;
            }
            console.log(`[AI Scores][${title}] å…± ${seen.size} å¯¹\n` + lines.join('\n'));
        } catch (e) {
            console.warn('[Workflow] å¯è¯»åŒ–è¯„åˆ†æ—¥å¿—è¾“å‡ºå¤±è´¥ï¼š', e);
        }
    }

    private dedupePairs(pairs: NotePairScore[]): NotePairScore[] {
        const seen = new Set<string>();
        const result: NotePairScore[] = [];
        for (const p of pairs) {
            const key = p.note_id_1 < p.note_id_2 ? `${p.note_id_1}:${p.note_id_2}` : `${p.note_id_2}:${p.note_id_1}`;
            if (seen.has(key)) continue;
            seen.add(key);
            result.push(p);
        }
        return result;
    }
}
